---
title: "Lock-free без сборки мусора"
author: Aaron Turon (перевёл Сергей Ефремов)
categories: обучение
excerpt: >
    В статье описывается реализация библиотеки crossbeam.
---

Это перевод [статьи](https://aturon.github.io/blog/2015/08/27/epoch/).

В нашей среде широко распространена мысль о том, что одним из преимуществ
сборщика мусора является простота разработки высоко-производительных lock-free
структур данных. Ручное управление памятью в них сделать не просто, а GC с
легкостью решает эту проблему.

Этот пост покажет, что, используя Rust, можно построить API управления памятью
для конкурентных структур данных, которое:

*   Сделает возможным реализацию lock-free структуры данных, как это делает GC;
*   Создаст статическую защиту от неправильного использования схемы управления памятью;
*   Будет иметь сравнимые с GC накладные расходы (и более предсказуемые).

В тестах, которые я покажу ниже, Rust легко превосходит реализации lock-free
очередей в Java, а саму реализацию на Rust легко написать.

Я реализовал схему управления памятью, основанную на эпохах (“epoch-based memory
reclamation”) в новой библиотеке Crossbeam, которая на сегодняшний день готова к
использованию с вашими структурами данных. В этом посте я расскажу о lock-free
структурах данных, алгоритме эпох, и внутреннем API Rust.


# Тесты

Перед тем, как погрузиться в глубины спроектированного API и использованию эпох
в управлении памятью, перейдем к главному: производительности.

Для сравнения накладных расходов моей реализации в Crossbeam с реализацией с
полноценным GC, я для начала реализовал базовый алгоритм lock-free очереди
(классическая очередь Michael-Scott), и создал точно такую же очередь в Scala. В
общем случае языки на основе JVM прекрасно подходят для построения lock-free
структур данных “с полноценным GC”.

В дополнении к этим реализациям, я производил сравнения с:

*   Более эффективной “сегментированной” очередью, которая располагает элементы в
нескольких слотах. Я написал эту очередь на Rust еще на заре Crossbeam.

*   Однопоточной очередью на Rust, защищающуюся мьютексом.

*   Реализацией очереди java.util.concurrent (ConcurrentLinkedQueue), которая 
представляет собой доработанный вариант очереди Michael-Scott.

Я тестировал очереди двумя способами:

Сценарий с множеством производителей и одним потребителем (A multi-producer,
single-consumer (MPSC)), в котором два потока неоднократно посылают сообщения, а
один поток получает их в непрервном цикле.

Сценарий с множеством производителей и множеством потребителей (A multi-
producer, multi-consumer (MPMC)), в котором два потока посылают и два потока
принимают в непрерывном цикле.

Тесты подобные этим довольно типичны для измерения масштабируемости lock-free
структур данных в режиме “соперничества – множество потоков одновременно борются
за конкурентное обновление. Необходимо тестировать много вариантов использования
очереди при построении реализации для production; здесь цель - это просто
приблизительно оценить накладные расходы схемы управления памятью.

Для теста MPSC я также добавил сравнение с встроенным в Rust алгоритмом каналов,
который как раз оптимизирован под этот вариант использования (и, следовательно,
не поддерживает MPMC).

Использовалась машина - 4 ядра 2.6Ghz Intel Core i7 и 16GB RAM.

Вот результаты, дающиеся в количество наносекунд на сообщение (меньше лучше):





# Анализ

Главный вывод - это то, что реализация в Crossbeam – которая не дорабатывали под
конкретные случаи – конкурентоспособна во всех случаях. Можно сделать лучше
реализацию и на Rust и на JVM, используя более умные или специализированные
очереди, но по крайней мере эти результаты показывают, что накладные расходы
схемы управления памятью, основанную на эпохах, оправдывают себя.robust

Заметьте, что версии Java/Scala гораздо лучше ведут себя в тесте MPMC, чем в
MPSC. Почему так?

Ответ прост: сборщик мусора. В тесте MPSC производители, как правило, обгоняют
потребителя по времени, что означает, что количество данных в очереди медленно
растет. Что в свою очередь увеличивает цену каждой сборки мусора, заставляя
сборщика проходить по увеличивающемуся живому набору данных.

В схеме эпох, наоборот, цена управления мусором относительно фиксированна: она
пропорциональна количеству потоков, а не количеству живых данных. Из этого
следует как лучшая, так и более постоянная/предсказуемая производительность.

Наконец, один вариант, который я не включил в график сравнений (потому что он
сильно отстает от других), был с использованием Mutex во время извлечения из
очереди, написанный на Rust. Для теста MPMC производительность была около
3040ns/операция, что в 20 раз медленнее, чем реализация из Crossbeam. Это
наглядная демонстрация того, почему важны lock-free структуры данных – начнем же
погружаться в них.

# Lock-free структуры данных

Если вы хотите использовать (и изменять) структуру данных из нескольких
конкурирующих потоков, вам нужна синхронизация. Самое простое решение это
глобальный lock – в Rust можно обернуть внутреннюю структуру данных в Mutex и
вызывать ее хоть целый день.

Проблема в том, что такая “грубая” синхронизация означает, что несколько потоков
постоянно должны координировать свой доступ к структуре данных, даже если они
обращаются к непересекающимся ее частям. Это также означает, что если поток
только пытается читать, он должен выполнить запись, обновляя статус lock – и из-
за того, что lock - это глобальная точка связи, такие записи приводят к большому
количеству трафика инвалидации кэша. Даже если вы используете несколько более
"тонких" lock, появляются другие угрозы, такие как дедлок и инверсия
приоритетов, и все равно производительность сильно падает.

Гораздо радикальной альтернативой являются lock-free структуры данных, которые
используют атомарные операции для выполнения изменений напрямую в структуре
данных без дальнейшей синхронизации. Зачастую они быстрее, лучше масштабируются,
и надежнее, чем lock-based алгоритмы.

Я не буду пытаться дать полный обзор по lock-free программированию в этом посте,
но главный посыл, который надо понимать, это то, что если у вас нет глобальной
синхронизации, то очень сложно сказать, когда же можно освободить память.
Множество опубликованных алгоритмов обычно подразумевают, что есть сборщик
мусора или какой-то другой способ восстановления памяти. Поэтому прежде чем
отправиться по lock-free параллельности в Rust, нужно рассказать про
восстановление памяти – и именно об этом пойдет речь в данном посте.

# Стек Treiber'а

Для большей конкретики, взглянем на “Hello world” в lock-free структурах данных:
стек Treiber’а. Стек представляет собой односвязный список, а все изменения
касаются указателя на head:

```rust
#![feature(box_raw)]

use std::ptr::{self, null_mut};
use std::sync::atomic::AtomicPtr;
use std::sync::atomic::Ordering::{Relaxed, Release, Acquire};

pub struct Stack<T> {
    head: AtomicPtr<Node<T>>,
}

struct Node<T> {
    data: T,
    next: *mut Node<T>,
}

impl<T> Stack<T> {
    pub fn new() -> Stack<T> {
        Stack {
            head: AtomicPtr::new(null_mut()),
        }
    }
}
```

Самое простое начать с метода pop. Для этого, заходим в цикл, берем слепок head
и выполняем compare-and-swap, заменяющий слепок на указатель на следующий
элемент:

Заметьте, что compare_and_swap автоматически меняет значение AtomicPtr со
старого значения на новое, если старое значение совпадает. В этом посте также
можете спокойно пропускать метки Acquire, Release и Relaxed, если они вам не
знакомы.

```rust
impl<T> Stack<T> {
    pub fn pop(&self) -> Option<T> {
        loop {
            // делаем слепок
            let head = self.head.load(Acquire);

            // проверяем, что стек не пустой
            if head == null_mut() {
                return None
            } else {
                let next = unsafe { (*head).next };

                // если слепок все еще хороший, заменяем `head` на `next`
                if self.head.compare_and_swap(head, next, Release) == head {

                    // вытаскиваем данные узла, больше ни с кем не связанного 
                    // **ВНИМАНИЕ**: утечка узла!
                    return Some(unsafe { ptr::read(&(*head).data) })
                }
            }
        }
    }
}
```

Функция ptr::read - это способ передать владение данными в Rust без статического
или динамического отслеживания этого. Здесь мы используем атомарность
compare_and_swap, чтобы гарантировать, что только один поток вызовет ptr::read –
а, как мы увидим, эта реализация никогда не освобождает узлы из памяти, поэтому
деструктор данных никогда не вызывается. Эти два факта вместе делают
использование ptr::read безопасным.

Метод Push похож на это:

```rust
impl<T> Stack<T> {
    pub fn push(&self, t: T) {
        // размещаем в памяти узел, и сразу же превращаем его в *mut pointer
        let n = Box::into_raw(Box::new(Node {
            data: t,
            next: null_mut(),
        }));
        loop {
            // делаем слепок текущей head
            let head = self.head.load(Relaxed);

            // обновляем указатель `next` на слепок
            unsafe { (*n).next = head; }

            // если слепок все еще хороший, связываем новый узел
            if self.head.compare_and_swap(head, n, Release) == head {
                break
            }
        }
    }
}
```

# Проблема

Если бы мы написали этот код в языке с GC, то на этом бы все и закончилось. Но
как написано сейчас в Rust, память будет утекать. В частности, реализация pop не
пытается освободить память по указателю в узле после его удаления из стека.

Что пойдет не так, если мы добавим освобождение памяти?

```rust
// вытаскиваем данные узла, больше ни с кем не связанного
let ret = Some(unsafe { ptr::read(&(*head).data) });

// освобождаем узел
mem::drop(Box::from_raw(head));

return ret
```

Проблема в том, что другие потоки могли тоже в этот же момент вызывать pop. У
них может быть слепок текущей head; ничего не ограничивает их от чтения
(*head).next их слепка сразу после того как мы освободили узел, на который
они ссылаются –  в самом явном виде баг использование-после-освобождения!

Вот в этом то и суть вопроса. Мы хотим использовать lock-free алгоритмы, но
многое в них приведет к поведению аналогичному поведению стека выше, оставляя
нас в полном неведении, когда же можно безопасно удалить узел. И что дальше?

# Схема управления памятью, основанная на эпохах

Есть несколько не основанных на GC способах управления памятью для lock-free
кода, но все они сводятся к одним и тем же наблюдениям:

1. Здесь есть два варианта достать данные – из самой структуры данных и из
слепков в потоках, обращающихся к структуре. Прежде чем мы удалим какой-либо
узел, мы должны быть уверены, что его нельзя достать ни одним из этих способов.

2. Когда узел отделен от структуры данных, нельзя будем создать слепок, который
может достать его.

Одной из самых элегантных и многообещающих является схема, основанная на эпохах
Keir Fraser’а, которая была описана в свободных терминах в его докторской
диссертации.

Основной идеей является спрятать подальше отделенные узлы от структуры данных
(первый вариант доступа к данным) до тех пор пока их можно будет безопасно
удалить. Прежде, чем мы можем удалить спрятанный узел, нам надо знать, что все
потоки обращавшиеся к структуре данных в это время уже закончили свою работу.
Наблюдение 2 выше подразумевает, что не осталось слепков спрятанного узла (из-за
того, что новые слепки не могли создастся в это время). Самой сложной частью
является сделать это все без синхронизации. Иначе мы потеряем выигрыш, который и
должна приносить нам свобода от блокировок в первую очередь!

Схема эпох работает, обладая следующим:

1.Глобальный счетчик эпохи ( принимающий значения 0, 1 и 2);
2.Глобальный список мусора для каждой эпохи;
3.Флаг “активности” для каждого потока;
4.Счетчик эпохи для каждого потока.

Эпохи нужны, чтобы понять когда мусор можно безопасно освободить из памяти,
потому что он не доступен ни одному из потоков. В отличие от традиционного GC
это не требует прохода по живым данным; это сугубо проверка счетчиков эпох.

Если поток хочет выполнить какую-нибудь операцию со структурой данных, он
сначала поднимает свой флаг “активности”, и затем обновляет свою локальную
эпоху, чтобы она совпадала с глобальной. Если поток удаляет узел из структуры
данных, он добавляет этот узел в список мусор текущей глобальной эпохи.
(Внимание: очень важно, чтобы мусор шел в текущей глобальной эпохе, а не в
предыдущем локальном слепке.) После окончания операции, поток чистит флаг
“активности”.

Для того, чтобы попытаться собрать мусор (что можно сделать в любой момент),
поток проходится по флагам всех участвующих потоков и проверяет все ли активные
потоки находятся в текущей эпохе. Если это так, он может попытаться увеличить
глобальную эпоху (по модулю 3). Если инкремент проходит успешно, мусор из двух
эпох назад может быть освобожден из памяти.

Зачем нам три эпохи? Потому что “сборка мусора” происходит параллельно, а потоки
могут находится в одной из двух эпох в любой момент (еще в “старой” или уже
“новой”). Но из- за того, что мы проверяем, что все активные потоки находятся в
старой эпохе перед ее увеличением, мы гарантируем, что ни один из потоков не
находится в третьей эпохе.

Эта схема спроектирована так, что большинство времени потоки имеют дело с
данными, который уже в кэше или (обычно) локальны для них. Только выполнение
“GC” включает в себя изменение глобальной эпохи или чтение эпох других потоков.
Подход управления памятью с помощью эпох не зависит от алгоритма структуры
данных, прост в использовании, а его производительность конкурентоспособна с
другими подходами.

Оказалось, что он прекрасно ложится на систему владений Rust.

# Rust API

Мы хотим, чтобы Rust API отражало базовые принципы управления памятью,
основанной на эпохах:

*   При работе со структурой общих данных, поток должен быть всегда в “активном” 
состоянии.

*   Если поток активен, все прочтенные данные из структуры остаются размещенными
в памяти до тех пор пока поток не станет неактивным.

Мы усилим систему владений Rust – в частности, управление ресурсами на основе
владения (RAII) – чтобы она ловила эти ограничения напрямую в сигнатурах типов
API эпох. Это в свою очередь докажет, что мы используем правильно управление
эпохами.

# Guard

Для работы с lock-free структурой данных, для начала надо получить защитника,
который является владеемым значением, говорящим о том, что ваш поток активен:

```rust
pub struct Guard { ... }
pub fn pin() -> Guard;
```

Функция pin дает потоку флаг активности, загружает глобальную эпоху, и может
попытаться выполнить GC (объясняется чуть позже в посте). Деструктор Guard, с
другой стороны, выходит из управления эпохами помечая поток флагом неактивности.

В связи с тем, что Guard представляет собой “активность”, заимствованный &'a Guard
гарантирует, что поток активен на время жизни 'a – именно то что нам нужно,
чтобы ограничить время жизни слепка, взятого в lock-free алгоритме.

Для использования Guard, Crossbeam предоставляет набор из трех типов указателей,
предназначенных для совместной работы:

*   Owned<T>, сродни Box<T>, который указывает на уникально владеемые данные,
которые еще не были добавлены в конкурентную структуру данных.

*   Shared<'a, T>, сродни &'a T, который указывает на разделяемые данные, 
которые могут или не могут быть доступны из структуры данных, но он гарантирует,
 что они не будут освобождены из памяти в течение времени жизни 'a.

*   Atomic<T>, сродни std::sync::atomic::AtomicPtr, который предоставляет 
атомарное обновление указателя, используя типы Owned и Shared, и связывает их с 
Guard.

Рассмотрим каждый из них .

# Указатели Owned и Shared 

Указатель Owned обладает похожим на Box интерфейсом:

```rust
pub struct Owned<T> { ... }

impl<T> Owned<T> {
    pub fn new(t: T) -> Owned<T>;
}

impl<T> Deref for Owned<T> {
    type Target = T;
    ...
}
impl<T> DerefMut for Owned<T> { ... }
```

Указатель Shared<'a, T> похож на &'a T – он реализует Copy – но разыменовывается
в &'a T. Это такой хитрый способ передать, что время жизни указателя, который он
предоставляет на самом деле равно 'a.

```rust
pub struct Shared<'a, T: 'a> { ... }

impl<'a, T> Copy for Shared<'a, T> { ... }
impl<'a, T> Clone for Shared<'a, T> { ... }

impl<'a, T> Deref for Shared<'a, T> {
    type Target = &'a T;
    ...
}
```

В отличие от Owned, нельзя напрямую создать указатель Shared. Вместо этого,
указатели Shared получаются по средствам чтения из Atomic, что мы увидим далее.

# Atomic

Сердцем библиотеки является Atomic, который предоставляет атомарный доступ к
указателю (может быть null), и связывает между собой другие типы в библиотеке:

```rust
pub struct Atomic<T> { ... }

impl<T> Atomic<T> {
    /// создает новый, нулевой атомарный указатель.
    pub fn null() -> Atomic<T>;
}
```

Рассмотрим по очереди каждую операцию, из их хитрости в определенные моменты.

# Загрузка

Во-первых, загрузка из Atomic:

```rust
impl<T> Atomic<T> {
    pub fn load<'a>(&self, ord: Ordering, _: &'a Guard) -> Option<Shared<'a, T>>;
}
```

Для выполнения загрузки, мы должны передать заимствованный Guard. Как
объяснялось выше, это способ гарантировать, что поток будет активен во время
жизни 'a. Возвращается опциональный Shared указатель (None если Atomic сейчас
равен null), с временем жизни, привязанным к защитнику.

Интересно сравнить это с интерфейсом AtomicPtr из стандартной библиотеки, в
которой загрузка возвращает *mut T. Из-за использования эпох, мы можем
гарантировать безопасное разыменование указателя во время жизни 'a, в то время
как с AtomicPtr этого ничего нет.

# Сохранение

Сохранение немного посложнее, потому что в деле есть несколько типов указателей.

Если мы просто хотим сохранить Owned указатель или нулевое значение, нам не
нужно, чтобы поток был активным. Мы просто передаем владение в структуру данных,
и нам не нужно никаких гарантий времен жизни указателей:

```rust
impl<T> Atomic<T> {
    pub fn store(&self, val: Option<Owned<T>>, ord: Ordering);
}
```

Хотя иногда мы хотим передать владение структуре данных и немедленно получить
указатель на переданные данные – например, потому что нам надо добавить
дополнительные связи в этот же узел в структуре данных. В этом случае нам надо
привязать время жизни к защитнику:

```rust
impl<T> Atomic<T> {
    pub fn store_and_ref<'a>(&self,
                             val: Owned<T>,
                             ord: Ordering,
                             _: &'a Guard)
                             -> Shared<'a, T>;
}
```

Заметьте, что представление во время исполнения у val и возвращаемого значения
абсолютно одинаковое – мы передаем указатель внутрь и получаем тот же указатель
снаружи. Но ситуация с владениями с точки зрения Rust на этом шаге кардинально
меняется.

Наконец, мы можем сохранить указатель в структуре данных:

```rust
impl<T> Atomic<T> {
    pub fn store_shared(&self, val: Option<Shared<T>>, ord: Ordering);
}
```

Защитник здесь не нужен, потому что мы не узнаем никакой новой информации о
времени жизни указателя.

# CAS

Следующее, что у нас есть - это семейство операций compare-and-set. Самый
простой случай - это заменить Shared указатель на новый Owned указатель:

```rust
impl<T> Atomic<T> {
    pub fn cas(&self,
               old: Option<Shared<T>>,
               new: Option<Owned<T>>,
               ord: Ordering)
               -> Result<(), Option<Owned<T>>>;
}
```

Также как и с сохранением, этой операции не нужен защитник; он не добавит
никакой новой информации о времени жизни. Result показывает удачен ли CAS; если
нет, то владение новым указателем возвращается тому, кто вызвал эту функцию.

Дальше у нас есть аналог store_and_ref:

```rust
impl<T> Atomic<T> {
    pub fn cas_and_ref<'a>(&self,
                           old: Option<Shared<T>>,
                           new: Owned<T>,
                           ord: Ordering,
                           _: &'a Guard)
                           -> Result<Shared<'a, T>, Owned<T>>;
```

В этом случае, при удачном CAS мы получим Shared указатель на вставленные нами
данные.

Последнее, мы можем заменить один Shared указатель другим:

```rust
impl<T> Atomic<T> {
    pub fn cas_shared(&self,
                             old: Option<Shared<T>>,
                             new: Option<Shared<T>>,
                             ord: Ordering)
                             -> bool;
}
```

Возвращаемое булевое значение равно true когда CAS успешен.

# Освобождение памяти

Конечно, все перечисленные механизмы служат одной цели: по-настоящему освободить
память, которая больше не достижима. Когда узел отделили от структуры данных,
поток, который отделил его, может проинформировать своего Guard, что память
должна быть очищена:

impl Guard {
    pub unsafe fn unlinked<T>(&self, val: Shared<T>);
}

Эта операция добавляет Shared указатель в соответствующий список мусора,
позволяя ей быть очищенной две эпохи спустя.

Операция небезопасна, потому что она подразумевает, что:

*   Shared указатель не доступен из структуры данных,
*   ни один другой поток не вызовет отделение этого узла.

Это важно, хотя, другие потоки могут продолжить ссылаться на этот Shared
указатель; система эпох гарантирует, что ни один из потоков не будет ссылаться
на узел после его настоящего освобождения из памяти.

Здесь нет конкретной связи между временем жизни Shared указателя и Guard; если у
нас есть достижимый Shared указатель, то мы знаем, что защитник, из которого он
пришел, все еще активен.

# Стек Treiber’а с эпохами

Без дальнейших пояснений, пот код стека Treiber’а, использующий API эпох
Crossbeam:

```rust
use std::sync::atomic::Ordering::{Acquire, Release, Relaxed};
use std::ptr;

use crossbeam::mem::epoch::{self, Atomic, Owned};

pub struct TreiberStack<T> {
    head: Atomic<Node<T>>,
}

struct Node<T> {
    data: T,
    next: Atomic<Node<T>>,
}

impl<T> TreiberStack<T> {
    pub fn new() -> TreiberStack<T> {
        TreiberStack {
            head: Atomic::new()
        }
    }

    pub fn push(&self, t: T) {
        // allocate the node via Owned
        let mut n = Owned::new(Node {
            data: t,
            next: Atomic::new(),
        });

        // become active
        let guard = epoch::pin();

        loop {
            // snapshot current head
            let head = self.head.load(Relaxed, &guard);

            // update `next` pointer with snapshot
            n.next.store_shared(head, Relaxed);

            // if snapshot is still good, link in the new node
            match self.head.cas_and_ref(head, n, Release, &guard) {
                Ok(_) => return,
                Err(owned) => n = owned,
            }
        }
    }

    pub fn pop(&self) -> Option<T> {
        // become active
        let guard = epoch::pin();

        loop {
            // take a snapshot
            match self.head.load(Acquire, &guard) {
                // the stack is non-empty
                Some(head) => {
                    // read through the snapshot, *safely*!
                    let next = head.next.load(Relaxed, &guard);

                    // if snapshot is still good, update from `head` to `next`
                    if self.head.cas_shared(Some(head), next, Release) {
                        unsafe {
                            // mark the node as unlinked
                            guard.unlinked(head);

                            // extract out the data from the now-unlinked node
                            return Some(ptr::read(&(*head).data))
                        }
                    }
                }

                // we observed the stack empty
                None => return None
            }
        }
    }
}
```

Some obserations:

The basic logic of the algorithm is identical to the version that relies on a
GC, except that we explicitly flag the popped node as “unlinked”. In general,
it’s possible to take lock-free algorithms “off the shelf” (the ones on the
shelf generally assume a GC) and code them up directly against Crossbeam in this
way.

After we take a snapshot, we can dereference it without using unsafe, because
the guard guarantees its liveness.

The use of ptr::read here is justified by our use of compare-and-swap to ensure
that only one thread calls it, and the fact that the epoch reclamation scheme
does not run destructors, but merely deallocates memory.

The last point about deallocation deserves a bit more comment, so let’s wrap up
the API description by talking about garbage.

# Managing garbage

The design in Crossbeam treats epoch management as a service shared by all data
structures: there is a single static for global epoch state, and a single
thread-local for the per-thread state. This makes the epoch API very simple to
use, since there’s no per-data structure setup. It also means the (rather
trivial) space usage is tied to the number of threads using epochs, not the
number of data structures.

One difference in Crossbeam’s implementation from the existing literature on
epochs is that each thread keeps local garbage lists. That is, when a thread
marks a node as “unlinked” that node is added to some thread-local data, rather
than immediately to a global garbage list (which would require additional
synchronization).

Each time you call epoch::pin(), the current thread will check whether its local
garbage has surpassed a collection threshold, and if so, it will attempt a
collection. Likewise, whenever you call epoch::pin(), if the global epoch has
advanced past the previous snapshot, the current thread can collect some of its
garbage. Besides avoiding global synchronization around the garbage lists, this
new scheme spreads out the work of actually freeing memory among all the threads
accessing a data structure.

Because GC can only occur if all active threads are on the current epoch, it’s
not always possible to collect. But in practice, the garbage on a given thread
rarely exceeds the threshold.

There’s one catch, though: because GC can fail, if a thread is exiting, it needs
to do something with its garbage. So the Crossbeam implementation also has
global garbage lists, which are used as a last-ditch place to throw garbage when
a thread exits. These global garbage lists are collected by the thread that
successfully increments the global epoch.

Finally, what does it mean to “collect” the garbage? As mentioned above, the
library only deallocates the memory; it does not run destructors.

Conceptually, the framework splits up the destruction of an object into two
pieces: destroying/moving out interior data, and deallocating the object
containing it. The former should happen at the same time as invoking unlinked –
that’s the point where there is a unique thread that owns the object in every
sense except the ability to actually deallocate it. The latter happens at some
unknown later point, when the object is known to no longer be referenced. This
does impose an obligation on the user: access through a snapshot should only
read data that will be valid until deallocation. But this is basically always
the case for lock-free data structures, which tend to have a clear split between
data relevant to the container (i.e., Atomic fields), and the actual data
contained (like the data field in Node).

Splitting up the tear down of an object this way means that destructors run
synchronously, at predictable times, alleviating one of the pain points of GC,
and allowing the framework to be used with non-'static (and non-Send) data.

# The road ahead

Crossbeam is still in its infancy. The work here is laying the foundation for
exploring a wide range of lock-free data structures in Rust, and I hope for
Crossbeam to eventually play a role similar to java.util.concurrent for Rust –
including a lock-free hashmap, work-stealing deques, and lightweight task
engine. If you’re interested in this work, I’d love to have help!

Related Posts
Resurrecting impl Trait 28 Sep 2015
Specialize to reuse 18 Sep 2015
© 2015. All rights reserved.
